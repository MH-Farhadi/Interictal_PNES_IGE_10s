{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n",
      "INFO:__main__:Generating dummy data...\n",
      "INFO:__main__:Preprocessing data...\n",
      "C:\\Users\\mhfar\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "INFO:__main__:Starting training...\n",
      "INFO:__main__:Epoch 1/10\n",
      "  0%|          | 0/25 [00:05<?, ?it/s]\n",
      "ERROR:__main__:An error occurred during execution: DataLoader worker (pid(s) 17660, 23240, 4932, 7336) exited unexpectedly\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 17660, 23240, 4932, 7336) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 595\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    593\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m--> 595\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 580\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 580\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[1], line 365\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    362\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[0;32m    368\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "Cell \u001b[1;32mIn[1], line 308\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    306\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target, spike_annot) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)):\n\u001b[0;32m    309\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 17660, 23240, 4932, 7336) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import butter, filtfilt\n",
    "import math\n",
    "import os\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpatialSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial self-attention module for processing temporal EEG data.\n",
    "    Applies attention across the time dimension for each channel.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, dk: int = 32):\n",
    "        super().__init__()\n",
    "        self.dk = dk\n",
    "        \n",
    "        # Projections for Query, Key, Value\n",
    "        self.query_conv = nn.Conv1d(in_channels, dk, 1)\n",
    "        self.key_conv = nn.Conv1d(in_channels, dk, 1)\n",
    "        self.value_conv = nn.Conv1d(in_channels, in_channels, 1)\n",
    "        \n",
    "        self.out_proj = nn.Conv1d(in_channels, in_channels, 1)\n",
    "        self.layer_norm = nn.LayerNorm([in_channels])\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size, C, L = x.size()\n",
    "        \n",
    "        # Create Q, K, V projections\n",
    "        Q = self.query_conv(x)\n",
    "        K = self.key_conv(x)\n",
    "        V = self.value_conv(x)\n",
    "        \n",
    "        # Reshape for attention computation\n",
    "        Q = Q.permute(0, 2, 1)\n",
    "        K = K.permute(0, 2, 1)\n",
    "        V = V.permute(0, 2, 1)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attn = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.dk)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.matmul(attn, V).permute(0, 2, 1)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        # Residual connection and normalization\n",
    "        out = x + out\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.layer_norm(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        \n",
    "        return out, attn\n",
    "\n",
    "class CrossChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross-channel attention module for modeling relationships between EEG channels.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, dk: int = 32):\n",
    "        super().__init__()\n",
    "        self.dk = dk\n",
    "        \n",
    "        self.q_proj = nn.Linear(in_channels, dk)\n",
    "        self.k_proj = nn.Linear(in_channels, dk)\n",
    "        self.v_proj = nn.Linear(in_channels, in_channels)\n",
    "        \n",
    "        self.out_proj = nn.Linear(in_channels, in_channels)\n",
    "        self.layer_norm = nn.LayerNorm(in_channels)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x_reshaped = x.permute(0, 2, 1)\n",
    "        \n",
    "        Q = self.q_proj(x_reshaped)\n",
    "        K = self.k_proj(x_reshaped)\n",
    "        V = self.v_proj(x_reshaped)\n",
    "        \n",
    "        attn = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.dk)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        out = torch.matmul(attn, V)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        out = x_reshaped + out\n",
    "        out = self.layer_norm(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        \n",
    "        return out, attn\n",
    "\n",
    "class LocalSpikeDetectionBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Branch for detecting local spike patterns in EEG signals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size: int, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2,  # Changed to same padding\n",
    "            bias=True\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class EpilepsyDetectionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete model for epilepsy detection from EEG signals.\n",
    "    Combines multiple detection branches with attention mechanisms.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels: int = 32, sampling_rate: int = 300, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel_sizes = [\n",
    "            int(0.07 * sampling_rate),  # 70ms\n",
    "            int(0.15 * sampling_rate),  # 150ms\n",
    "            int(0.20 * sampling_rate)   # 200ms\n",
    "        ]\n",
    "        \n",
    "        self.branches = nn.ModuleList([\n",
    "            LocalSpikeDetectionBranch(k, num_channels, 128)\n",
    "            for k in self.kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        self.channel_conv = nn.Conv1d(384, 256, kernel_size=1)\n",
    "        self.spatial_attention = SpatialSelfAttention(256)\n",
    "        self.cross_channel_attention = CrossChannelAttention(256)\n",
    "        \n",
    "        # Adaptive pooling to handle variable input lengths\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(64)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, m: nn.Module):\n",
    "        if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.attention_weights = {}\n",
    "        \n",
    "        # Process each branch\n",
    "        branch_outputs = []\n",
    "        for branch in self.branches:\n",
    "            branch_outputs.append(branch(x))\n",
    "        \n",
    "        x = torch.cat(branch_outputs, dim=1)\n",
    "        x = self.channel_conv(x)\n",
    "        \n",
    "        x, spatial_attn = self.spatial_attention(x)\n",
    "        x, cross_attn = self.cross_channel_attention(x)\n",
    "        \n",
    "        self.attention_weights['spatial'] = spatial_attn\n",
    "        self.attention_weights['cross_channel'] = cross_attn\n",
    "        \n",
    "        # Adaptive pooling and classification\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    \"\"\"Dataset class for EEG data handling.\"\"\"\n",
    "    def __init__(self, eeg_data: np.ndarray, labels: np.ndarray, \n",
    "                 spike_annotations: Optional[np.ndarray] = None,\n",
    "                 transform: Optional[callable] = None):\n",
    "        self.eeg_data = torch.FloatTensor(eeg_data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "        self.spike_annotations = (torch.FloatTensor(spike_annotations) \n",
    "                                if spike_annotations is not None \n",
    "                                else torch.zeros_like(self.eeg_data))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.eeg_data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.eeg_data[idx]\n",
    "        y = self.labels[idx]\n",
    "        spikes = self.spike_annotations[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y, spikes\n",
    "\n",
    "class EEGAugmentation:\n",
    "    \"\"\"Data augmentation for EEG signals.\"\"\"\n",
    "    def __init__(self, noise_level: float = 0.01, \n",
    "                 shift_range: int = 15,\n",
    "                 scale_range: Tuple[float, float] = (0.9, 1.1)):\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_range = shift_range\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Add Gaussian noise\n",
    "        x = x + torch.randn_like(x) * self.noise_level\n",
    "\n",
    "        # Random time shift\n",
    "        if self.shift_range > 0:\n",
    "            shift = torch.randint(-self.shift_range, self.shift_range + 1, (1,))\n",
    "            x = torch.roll(x, shifts=shift.item(), dims=-1)\n",
    "\n",
    "        # Random scaling\n",
    "        if self.scale_range[0] < self.scale_range[1]:\n",
    "            scale = torch.empty(1).uniform_(*self.scale_range)\n",
    "            x = x * scale\n",
    "\n",
    "        return x\n",
    "\n",
    "def preprocess_eeg(raw_eeg: np.ndarray, sampling_rate: int = 300) -> np.ndarray:\n",
    "    \"\"\"Preprocess EEG data with filtering and normalization.\"\"\"\n",
    "    nyq = sampling_rate / 2\n",
    "    b, a = butter(4, [1/nyq, 45/nyq], btype='band')\n",
    "    \n",
    "    # Apply filter along the last axis\n",
    "    filtered_eeg = filtfilt(b, a, raw_eeg, axis=-1)\n",
    "    \n",
    "    # Z-score normalization\n",
    "    mean = filtered_eeg.mean(axis=-1, keepdims=True)\n",
    "    std = filtered_eeg.std(axis=-1, keepdims=True)\n",
    "    normalized_eeg = (filtered_eeg - mean) / (std + 1e-8)\n",
    "    \n",
    "    return normalized_eeg\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Training manager for the epilepsy detection model.\"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, \n",
    "                 scheduler, device, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        self.config.update({\n",
    "            'spike_lambda': 0.1,\n",
    "            'consistency_lambda': 0.05,\n",
    "            'spike_margin': 0.5,\n",
    "            'validation_interval': 100\n",
    "        })\n",
    "        \n",
    "        self.branch_activations = {}\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def get_activation(name):\n",
    "            def hook(module, input, output):\n",
    "                self.branch_activations[name] = output\n",
    "            return hook\n",
    "\n",
    "        for i, branch in enumerate(self.model.branches):\n",
    "            branch.conv.register_forward_hook(get_activation(f'branch_{i}'))\n",
    "\n",
    "    def _calculate_metrics(self, trues, preds):\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            trues, preds, average='binary'\n",
    "        )\n",
    "        conf_matrix = confusion_matrix(trues, preds)\n",
    "        \n",
    "        return {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for batch_idx, (data, target, spike_annot) in enumerate(tqdm(self.train_loader)):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            \n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred = output.max(1)[1]\n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            \n",
    "            if batch_idx % self.config['validation_interval'] == 0:\n",
    "                logger.info(f'Training batch {batch_idx}/{len(self.train_loader)}, '\n",
    "                          f'Loss: {loss.item():.6f}')\n",
    "        \n",
    "        metrics = self._calculate_metrics(true_labels, predictions)\n",
    "        metrics['train_loss'] = total_loss / len(self.train_loader)\n",
    "        \n",
    "        logger.info(f\"Training metrics: {metrics}\")\n",
    "        return metrics\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target, spike_annot in tqdm(self.val_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                \n",
    "                val_loss += self.criterion(output, target).item()\n",
    "                \n",
    "                pred = output.max(1)[1]\n",
    "                predictions.extend(pred.cpu().numpy())\n",
    "                true_labels.extend(target.cpu().numpy())\n",
    "        \n",
    "        metrics = self._calculate_metrics(true_labels, predictions)\n",
    "        metrics['val_loss'] = val_loss / len(self.val_loader)\n",
    "        \n",
    "        logger.info(f\"Validation metrics: {metrics}\")\n",
    "        return metrics\n",
    "\n",
    "    def train(self, epochs):\n",
    "        best_f1 = 0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            logger.info(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            # Training phase\n",
    "            train_metrics = self.train_epoch()\n",
    "            \n",
    "            # Validation phase\n",
    "            val_metrics = self.validate()\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_metrics['val_loss'])\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_metrics['f1'] > best_f1:\n",
    "                best_f1 = val_metrics['f1']\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
    "                logger.info(f\"New best model saved with F1: {best_f1:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= self.config['early_stopping_patience']:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "def generate_dummy_data(num_samples: int = 1000,\n",
    "                       num_channels: int = 32,\n",
    "                       sequence_length: int = 1000,\n",
    "                       sampling_rate: int = 300) -> Tuple[np.ndarray, ...]:\n",
    "    \"\"\"\n",
    "    Generate synthetic EEG data with epileptic patterns.\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of EEG recordings to generate\n",
    "        num_channels: Number of EEG channels\n",
    "        sequence_length: Length of each recording\n",
    "        sampling_rate: Sampling rate in Hz\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - raw_train_data: Training data\n",
    "        - train_labels: Training labels\n",
    "        - train_spike_annotations: Spike annotations for training\n",
    "        - raw_val_data: Validation data\n",
    "        - val_labels: Validation labels\n",
    "        - val_spike_annotations: Spike annotations for validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_normal_eeg(num_samples):\n",
    "        # Generate background EEG as pink noise\n",
    "        eeg = np.random.randn(num_samples, num_channels, sequence_length)\n",
    "        \n",
    "        # Add alpha rhythm (8-12 Hz)\n",
    "        t = np.linspace(0, sequence_length/sampling_rate, sequence_length)\n",
    "        alpha = np.sin(2 * np.pi * 10 * t)  # 10 Hz oscillation\n",
    "        eeg += 0.5 * alpha.reshape(1, 1, -1)\n",
    "        \n",
    "        # Add beta rhythm (13-30 Hz)\n",
    "        beta = np.sin(2 * np.pi * 20 * t)  # 20 Hz oscillation\n",
    "        eeg += 0.3 * beta.reshape(1, 1, -1)\n",
    "        \n",
    "        return eeg\n",
    "    \n",
    "    def generate_epileptic_spikes(eeg, num_spikes=5):\n",
    "        # Create spike template\n",
    "        spike_length = int(0.1 * sampling_rate)  # 100ms spike\n",
    "        spike = np.zeros(spike_length)\n",
    "        spike[:spike_length//2] = np.linspace(0, 1, spike_length//2)\n",
    "        spike[spike_length//2:] = np.linspace(1, 0, spike_length - spike_length//2)\n",
    "        \n",
    "        # Add spikes at random locations\n",
    "        spike_locations = np.zeros((eeg.shape[0], num_channels, sequence_length))\n",
    "        \n",
    "        for i in range(eeg.shape[0]):\n",
    "            if np.random.rand() > 0.5:  # 50% chance of epileptic sample\n",
    "                for _ in range(num_spikes):\n",
    "                    # Random start position\n",
    "                    start = np.random.randint(0, sequence_length - spike_length)\n",
    "                    \n",
    "                    # Select random subset of channels for the spike\n",
    "                    channels = np.random.choice(num_channels, size=num_channels//4, replace=False)\n",
    "                    \n",
    "                    # Add spike with random amplitude variation\n",
    "                    amplitude = np.random.uniform(1.5, 2.5)\n",
    "                    eeg[i, channels, start:start+spike_length] += amplitude * spike\n",
    "                    spike_locations[i, channels, start:start+spike_length] = 1\n",
    "                    \n",
    "                    # Add propagation effect to neighboring channels\n",
    "                    for ch in channels:\n",
    "                        if ch > 0:\n",
    "                            eeg[i, ch-1, start:start+spike_length] += 0.3 * amplitude * spike\n",
    "                        if ch < num_channels-1:\n",
    "                            eeg[i, ch+1, start:start+spike_length] += 0.3 * amplitude * spike\n",
    "        \n",
    "        return eeg, spike_locations\n",
    "\n",
    "    # Generate training data\n",
    "    total_samples = num_samples\n",
    "    train_samples = int(0.8 * total_samples)\n",
    "    \n",
    "    # Generate normal EEG\n",
    "    raw_train_data = generate_normal_eeg(train_samples)\n",
    "    raw_val_data = generate_normal_eeg(total_samples - train_samples)\n",
    "    \n",
    "    # Add epileptic spikes and get annotations\n",
    "    raw_train_data, train_spike_annotations = generate_epileptic_spikes(raw_train_data)\n",
    "    raw_val_data, val_spike_annotations = generate_epileptic_spikes(raw_val_data)\n",
    "    \n",
    "    # Generate labels (1 if contains spikes, 0 otherwise)\n",
    "    train_labels = (train_spike_annotations.sum(axis=(1, 2)) > 0).astype(int)\n",
    "    val_labels = (val_spike_annotations.sum(axis=(1, 2)) > 0).astype(int)\n",
    "    \n",
    "    return (raw_train_data, train_labels, train_spike_annotations,\n",
    "            raw_val_data, val_labels, val_spike_annotations)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'epochs': 10,  # Reduced for demonstration\n",
    "        'early_stopping_patience': 3,\n",
    "        'sampling_rate': 300,\n",
    "        'spike_lambda': 0.1,\n",
    "        'consistency_lambda': 0.05,\n",
    "        'spike_margin': 0.5,\n",
    "        'num_channels': 32,\n",
    "        'sequence_length': 1000,\n",
    "        'num_samples': 1000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Generate dummy data\n",
    "        logger.info(\"Generating dummy data...\")\n",
    "        (raw_train_data, train_labels, train_spike_annotations,\n",
    "         raw_val_data, val_labels, val_spike_annotations) = generate_dummy_data(\n",
    "            num_samples=config['num_samples'],\n",
    "            num_channels=config['num_channels'],\n",
    "            sequence_length=config['sequence_length'],\n",
    "            sampling_rate=config['sampling_rate']\n",
    "        )\n",
    "\n",
    "        # Preprocess data\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        train_data = preprocess_eeg(raw_train_data, config['sampling_rate'])\n",
    "        val_data = preprocess_eeg(raw_val_data, config['sampling_rate'])\n",
    "\n",
    "        # Create datasets\n",
    "        train_transform = EEGAugmentation()\n",
    "        train_dataset = EEGDataset(\n",
    "            train_data, \n",
    "            train_labels, \n",
    "            spike_annotations=train_spike_annotations,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        val_dataset = EEGDataset(\n",
    "            val_data, \n",
    "            val_labels,\n",
    "            spike_annotations=val_spike_annotations\n",
    "        )\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config['batch_size'],\n",
    "            shuffle=True, \n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=config['batch_size'],\n",
    "            shuffle=False, \n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        # Initialize model and training components\n",
    "        model = EpilepsyDetectionModel(\n",
    "            num_channels=config['num_channels'],\n",
    "            sampling_rate=config['sampling_rate']\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # Initialize trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        logger.info(\"Starting training...\")\n",
    "        trainer.train(config['epochs'])\n",
    "\n",
    "        logger.info(\"Training completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
